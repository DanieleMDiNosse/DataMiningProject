\documentclass[a4paper,9pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{gensymb}
\usepackage{colortbl}
\usepackage{multicol}
\usepackage{wrapfig}

\usepackage{amsmath,bm}
\usepackage{siunitx}
\usepackage{float}
\usepackage{hyperref}
\captionsetup{tableposition=top,figureposition=bottom,font=footnotesize}
\renewcommand{\vec}{\mathbf}
\usepackage{upgreek}
\usepackage[a4paper, total={7.7in, 10.5in}]{geometry}
\begin{document}
\title{Relazione del Progetto di Data Mining}
\title{%
  Relazione del Progetto di Data Mining \\
  \large Corso di Laurea Magistrale in Fisica \\
    Esame di Data Mining A.A. 2020/2021}
\author{Gruppo 33: Daniele Maria Di Nosse, Angelo Lasala, Raffaele Paradiso}
\maketitle
\newpage

\maketitle
\tableofcontents{}

\newpage

\section{Introduzione}
Determinare le possibili relazioni che intercorrono fra le caratteristiche dei dipendenti di un'azienda può risultare di grande utilità per predire i possibili scenari lavorativi che posso verificarsi e gestire di conseguenza l'organizzazione del personale in maniera ottimale. Nel presente progetto ci si è posto l'obiettivo di valutare tali legami tramite un approccio di data mining. Le informazioni che si sono utilizzate sono relative ad un data frame fittizio (leggermente modificato) generato da IBM e presente sul portale Kaggle(URL \url{https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset}). Non ci si è posto un obiettivo principale, ovvero la determinazione di legami, correlazioni e classificazioni relativi ad un singolo attributo rispetto a tutti gli altri, ma si è proceduto in maniera più generale ricoprendo uno spettro più ampio di possibili relazioni fra tutte le variabili.
\section{Data Understanding}
\subsection{Data Semantics}
Nella prima fase dell'elaborazione si è studiato il data frame, valutando il numero degli attributi, la loro natura e dominio. 

%\begin{center}
%\includegraphics[scale=0.5]{DFhead(10).png}
%\captionof{figure}{Primi 10 valori di ogni attributo}
%\end{center}
% trim=2cm 0 0 0cm

Il numero di attributi è pari a 33. Si dividono in attributi numerici e categorici, ma ad uno sguardo più attento si nota che alcuni di essi, come Education o EnviromentSatisfaction, presentano valori numerici che poco si adattano al loro significato. Si ha infatti che sussistono le seguenti relazioni: 

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\arrayrulecolor{white}\hline
Education & EnvironmentSatisfaction & JobInvolvement & JobSatisfaction \\
\arrayrulecolor{white}\hline
1 : 'Below College' & 1 : 'Low'  & 1 : 'Low'& 1 : 'Low' \\
2 : 'College'  & 2 : 'Medium' & 2 : 'Medium'& 2 : 'Medium'\\
3 : 'Bachelor'    &3 : 'High' & 3 : 'High'& 3 : 'High'  \\
4 : 'Master'    &4 : 'Very High' & 4 : 'Very High' & 4 : 'Very High' \\
5 : 'Doctor'  &  & &\\
\hline
\end{tabular}
\end{center}


%\begin{table}{I}{0.7\linewidth}
%\centering
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\arrayrulecolor{white}\hline
PerformanceRating & RelationshipSatisfaction&WorkLifeBalance  &   \quad\quad&\quad\quad    &\quad\quad      \\
\arrayrulecolor{white}\hline
1 : `Low' & 1 : `Low' & 1 : `Bad'&&&\\
2 : `Good' & 2 : 'Medium'& 2 : `Good'&&&\\
3 : `Excellent'& 3 : 'High' & 3 : `Better'&&&\\
4 : `Outstanding'& 4 : 'Very High' &4 : `Best'&&&\\
\hline
\end{tabular}
\end{center}

%\end{table}

Di conseguenza, il dominio di tali attributi è di tipo categorico od ordinale e non numerico (un attributo ordinale è effettivamente una sottocategoria categorica, si è scelto comunque di elencarli separatamente). Inoltre, sebbene non si abbiano informazioni dettagliate sulle classi relative agli attributi JobLevel e  StockOptionLevel, per la loro stessa natura si è deciso di trattarli come attributi ordinali. Organizzando tutte le variabili per la loro tipologia, si ottiene quindi la seguente suddivisione:

\begin{center}
\includegraphics[scale=0.50]{semantics.png}
\captionof{figure}{Domini degli attributi}
\end{center}
Per quanto riguarda il range di valori degli attributi risulta essere molto più discretizzato per gli attributi ordinali che per gli attributi numerici. Inoltre differisce molto da attributo ad attributo (anche di 4 ordini di grandezza), cosa che sottolinea sin da  ora l'importanza di una trasformazione delle variabili.

\subsection{Analisi statistica}
Le frequenze degli attributi categorici e le relative mode sono riportate nelle seguenti tabelle.

\begin{center}
\includegraphics[scale=1.28]{frequenza attributi nominali.png}
\captionof{figure}{Frequenze degli attributi categorici}
\end{center}

\begin{center}
\includegraphics[scale=1]{modacategoriciordinali.png}
\captionof{figure}{Mode}
\end{center}
 
 
Le distribuzioni degli attributi ordinali e numerici con alcuni indici statistici sono rappresentate di seguito.
Si può notare la forte asimmetria di molte distribuzioni ed un varianza molto grande in alcuni attributi. Tali problematiche dovranno essere sanate con opportune trasformazioni.

\begin{center}
\includegraphics[scale=1.1]{statistica.png}
\captionof{figure}{Indici statistici per gli attributi numerici}
\end{center}

\begin{center}
\includegraphics[scale=0.82,trim=0cm 0 0 0cm]{Istogrammi1.png}
\end{center}


\begin{center}
\includegraphics[scale=0.82,trim=0cm 0 0 0cm]{Istogrammi2.png}
\captionof{figure}{Istogrammi attributi numerici ed ordinali}
\end{center}

\subsection{Data Quality : Outliers e Missing values}
La qualità dei dati è fortemente influenzata negativamente dalla presenza di outliers e di missing values. Algoritmi di clustering e correlazioni fra gli attributi possono restituire risultati falsificati se non si gestiscono in maniera appropriata tali valori. 
Nel data frame utilizzato la loro presenza è evidente, infatti si ha che:

\begin{center}
\includegraphics[scale=1.5]{missingvalues.png}
\captionof{figure}{Count dei missing values}
\end{center}
Gli attributi StandardHours ed Over18 presentano una qualità molto scarsa: nel primo circa la metà dei records sono mancanti e la restante parte ha un unico valore, mentre il secondo, oltre a contenere anch'esso una quantità significativa di missing values, non rappresenta in ogni caso un attributo di grande importanza, considerando che la stragrande maggioranza dei dipendenti di un'azienda sono maggiorenni. Per tali motivi, si è deciso di eliminare questi due attributi.

Per la determinazione degli outliers sono stati utilizzati sia test puramente statistici (Grubbs's test) che metodi di visualizzazione (Box Plot, Principal Component Analysis e scatter plot). Come è noto, per utilizzare approcci del primo tipo bisogna fare delle assunzioni sulla distribuzione sottostante dei valori esaminati. In particolare, il Grubbs's test, applicabile singolarmente agli attributi, richiede che i dati siano distribuiti normalmente, cosa non vera in questo caso. Di conseguenza, tale metodo è stato scartato. 
Il Principal Component Analysis, d'altro canto, è uno dei metodi maggiormente utilizzati nella ricerca di outliers in situazioni alto-dimensionali. Proiettando lo spazio n-dimensionale in uno spazio q-dimensionale ($q<n$), costruito tramite i vettori normalizzati della matrice di correlazione, si cerca di mantenere il più intatta possibile la varianza negli attributi. Nel caso in esame, la frazione di varianza conservata non risulta essere significativa (circa $0.4$), inficiando inevitabilmente i risultati ottenuti.
Anche la visualizzazione degli scatter plot confrontati con gli attributi categorici non ha evidenziato alcun punto identificabile come outlier.
L'unico metodo che ha avuto successo per la loro determinazione è stata la visualizzazione dei Box Plot per i singoli attributi. Si è proceduto quindi alla loro rimozione tramite eliminazione delle righe corrispondenti.

\section{Data Preparation}
In questa fase del lavoro ci si è posto l'obiettivo di trasformare e preparare il set di dati all'analisi successiva. I problemi precedentemente evidenziati sono stati qui risolti.\\

Come primo task sono stati gestiti i missing values.
L'attributo BusinessTravel presenta una frequenza di NaN pari al circa $9\%$, confrontabile con le frequenze degli altri valori . Siccome la granulosità dell'attributo ricopre in maniera completa lo spettro delle classi plausibilmente ad esso associabili, si è deciso di valutare se ci fosse dipendenza con gli altri attributi nel data frame. Per quanto riguarda quella con i numerici, sono stati utilizzati gli scatter plot, mentre per quelli nominali è stato eseguito il test di indipendenza del chi quadro. In entrambi i casi non si sono evinte dipendenze significative ($p value > 0.05$ sempre). Di conseguenza tale attributo è stato scartato.\\
Per quanto riguarda PerformanceRating, si è aggiunta una nuova classe 'MISSING', poiché si è notato che la granulosità dell'attributo in questo caso non ricopre tutto lo spettro plausibile. Si presuppone che i valori `MISSING' possano appartenere ad una classe di ordine inferiore ad `Excellent'.\\
Queste due considerazioni non sono applicabili all'attributo Gender per il quale si è scelto semplicemente di sostituire ai missing values valori estratti dalla distibuzione del campione.\\
Procedimento analogo è stato applicato a tutti gli attributi numerici che presentano valori mancanti, l'unica differenza è che in questo caso i valori sostitutivi sono le medie degli intervalli dei bins degli istogrammi.\\ %(che al mercato mio padre comprò, nda).\\
Come secondo task sono stati valutati gli outliers.\\
Il metodo di visualizzazione grafica dei Box Plot evidenzia la presenza di outliers solo in tre attributi numerici: TrainingTimeLastYear, TotalWorkingYears, YearsAtCompany
\begin{center}
\includegraphics[scale=1]{boxplot.png}
\captionof{figure}{Box Plot degli attributi che presentano outliers}
\end{center}
 Il data frame dopo questa prima preparazione risulta contenere il $36\%$ di dati in meno rispetto a quello di partenza.\\
Funzioni di trasformazione sono state applicate ad attributi numerici con lo scopo di rimediare ad alcune caratteristiche delle loro distribuzioni, quali l'asimettrie e un valore spropositato della deviazione standar. In particolare è stata applicata la radice quadrata a DistanceFromHome (skew da 0.95 a 0.40), NumCompaniesWorked (skew da 1.03 a 0.03), PercentSalaryHike (skew da 0.82 a 0.65), TotalWorkingYears (skew da 1.12 a 0.18), YearsAtCompany (skew da 1.76 a 0.43), YearsInCurrentRole(skew da 0.92 a $-$0.25), YearsSinceLastPromotion (skew da 1.98 a 0.74) e YearsWithCurrManager (skew da 0.83 a $-$0.25); invece a MonthlyIncome è stato applicato il logaritmo naturale (varianza da 4710 a 0.67) . Di seguito sono riportate alcune distribuzioni delle variabili trasformate.\\

\begin{center}
\includegraphics[scale=0.35]{trasformer.png}
\captionof{figure}{Distribuzione di alcune variabili trasformate}
\end{center}

Come terzo task sono stati eliminati ed aggiunti nuovi attributi.\\
In luogo di TotalWorkingYears e YearsAtCompany si è scelto di introdurre il loro rapporto, denominato FractionAtCompany che rappresenta la frazione di anni lavorativi del singolo dipendente nell'azienda. Tramite l'introduzione di tale attributo è stato possibile notare l'inconsistenza di alcuni records per cui tale rapporto risultava essere maggiore di 1. Tali valori sono stati eliminati. Analogamente si è proceduto per MonthlyIncome e MonthlyRate sostituiti da RateIncome, indice di quanto l'azienda spende per un impiegato in rapporto al suo stipendio. Anche in questo caso sono stati eliminati i valori inconsistenti.\\ 
DailyRate e HourlyRate contengono la stessa informazione di MonthlyRate, quindi sono stati eliminati.\\
Inoltre, YearsInCurrentRole, YearInCurrManager e YearsSinceLastPromotion sono caratterizzati da una correlazione significativa e quindi si è deciso di mantenere solamente YearsInCurrentRole nell'analisi a seguire.\\
Infine è stata calcolata la matrice di correlazione lineare fra gli attributi numerici e i valori del $p $ $value$  ottenuti tramite test del chi quadro per l'interdipendenza fra gli attributi categorici.\\
Si può notare come il $p$ $ value$ per la maggioranza dei casi è maggiore di $0.05$, valore scelto come soglia; questo significa che l'ipotesi nulla (non c'è relazione tra i due attributi) non può essere scartata. Nell'altra situazione invece l'evidenza empirica è fortemente contraria all'ipotesi nulla, ciò significa che la presenza di una dipendenza tra gli attributi è statisticamente plausibile, come ad esempio avviene tra Attrition (quanto un impiegato è "logorato") e MaritialStatus (condizione sentimentale dell'impiegato).\\
Per gli attributi numerici, in seguito alle trasformazione effettuate, non sono presenti corelazioni significative.

\begin{center}
\includegraphics[scale=1.2]{mccat.png}
\captionof{figure}{Matrice dei $p$ $value$ per gli attributi categorici}
\end{center}

\begin{center}
\includegraphics[scale=1.2]{macnum.png}
\captionof{figure}{Matrice di correlazione per gli attributi numerici}
\end{center}

\section{Clustering}
Preparato il data frame si è proceduto all'analisi degli algoritmi di clustering: K-Means, DB Scan e Hierarchical. La dimensionalità del data frame ($10$) è stata considerata troppo elevata per ottenere risultati consistenti, quindi sono stati indagati sottoinsiemi 3-5 dimensionali alla ricerca un qualche tipo di clusterizzazione. Come metrica è stata usata la distanza euclidea.\\
Si vuole precisare che per la visualizzazione dei clusters ottenuti tramite K-Means e DB Scan è stato utilizzato uno spazio tridimensionale poichè, soprattutto nel primo caso, una visualizzazione bidimensionale portava ad un mixing eccesivo dei clusters stessi.

\subsection{K-Means}
Per quanto riguarda il K-Means i sottoinsiemi che hanno mostrato i risultati migliori sono:\\

\begin{enumerate}
\item PercentSalaryHike, FractionYearsAtCompany, YearsInCurrentRole, RateIncome, NumCompaniesWorked
\item DistanceFromHome, FractionYearsAtCompany, RateIncome, YearsInCurrentRole, TrainingTimesLastYear
\item DistanceFromHome, RateIncome, Age, FractionYearsAtCompany
\item DistanceFromHome, FractionYearsAtCompany, TrainingTimesLastYear, PercentSalaryHike, YearsInCurrentRole
\end{enumerate}


\begin{center}
\includegraphics[scale=0.6]{SSEsub1.png}
\captionof{figure}{SSE in funzione di $K$}
\end{center}

La scelta del numero di cluster $K$ è stata presa osservando l'andamento del SSE in funzione di $K$ (Figura $12$), simile in tutti e quattro i casi esaminati; con lo scopo di aver un buon compromesso fra i due l'algoritmo è stato eseguito per $K$ uguale a 3, 4 e 5. Dai risultati ottenuti si evince che, sebbene con $K=5$ il valore delle SSE è minore rispetto agli altri due casi, non si apprezzano cluster evidenti: ve ne sono sempre due eccessivamente mescolati. Con $K=3$ la divisione fra i clusters è sicuramente ben evidente ma, con $K=4$, si ottengono comunque buoni risultati con il vantaggio di un SSE minore. \\
Nei seguenti grafici sono mostrati i risultati ottenuti e per redendere più chiara la posizione dei centroidi, sono riportate anche le loro cordinate organizzate in parallelo per ciascun sottoinsieme usato.

\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[width=\textwidth]{parallelsub1.png}
\caption{Parallel coordinates dei centroidi}
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.55\textwidth}
\includegraphics[scale=0.6]{numcompan_Fraction_percentCENTROIDI.png}
\caption{Cluster sottoinsime 1: SSE$=187$; silhouette$=0.18$}
\label{etichetta2}
\end{minipage}
\end{figure}

\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[width=\textwidth]{par_cor2.png}
\caption{Parallel coordinates dei centroidi}
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.55\textwidth}
\includegraphics[scale=0.6]{rate_fraction_distance2.png}
\caption{Cluster sottoinsime 2: SSE$=177$; silhouette$=0.21$}
\label{etichetta2}
\end{minipage}
\end{figure}

\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[width=\textwidth]{par_cor_centroid8.png}
\caption{Parallel coordinates dei centroidi}
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.55\textwidth}
\includegraphics[scale=0.6]{rate_frac_dist8.png}
\caption{Cluster sottoinsime 3: SSE$=129$; silhouette$=0.25$}
\label{etichetta2}
\end{minipage}
\end{figure}

\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[width=\textwidth]{parr cor frac6.png}
\caption{Parallel coordinates dei centroidi}
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.55\textwidth}
\includegraphics[scale=0.6]{FractionYear_Distance_Percent_CENTROIDI6.png}
\caption{Cluster sottoinsime 4: SSE$=182$; silhouette$=0.20$}
\label{etichetta2}
\end{minipage}
\end{figure}

Dalla divisione in cluster è possibile classificare gli impiegati in base ad alcune caratteristiche comuni.
Ad esempio il cluster giallo nella Figura $13$  esprime l'irrilevanza dell'esperienza lavorativa al di fuori dell'azienda relativamente all'aumento di stipendio. Infatti chi è stato assunto da poco (rispetto alla vita lavorativa), sebbene abbia maturato esperienza in altre aziende, ha un percent salary hike basso.
D'altro canto, al cluster viola è plausibile associare i lavoratori la cui esperienza è costituita quasi esclusivamente da ruoli indipendenti da compagnie. Anche in questo caso, il percent salary hike è relativamente basso.
Il cluster blu può essere considerato il gruppo di lavoratori la cui esperienza non è stata influenzata da altri impieghi nel passato. Infatti si nota che in questo caso l'aumento percentuale dello stipendio è indipendente dal numero di compagnie precedenti.
Infine il cluster verde può essere visto come il gruppo di persone che hanno acquisito competenze utili all'azienda (ciò è evidente dalla percentuale di aumento di stipendio molto alta rispetto a tutti gli altri gruppi) in altri ambienti.\\
La classificazione fatta non è certamente da considerarsi assoluta, poiché dai valori della silhouette non elevati, si capisce che la distinzione tra i cluster non è netta: mescolamenti tra di essi sono molto plausibili.
Ragionamenti simili possono essere applicati agli altri grafici.

\subsubsection{Validazione}
Per quanto riguarda la validazione dei cluster ottenuti, si è valutata la distribuzione dell'SSE e della silhouette generati dal K-Means su un numero $N=500$ di set di dati random estratti dallo stesso dominio degli attributi usati. La clusterizzazione è quindi ritenuta non random se l'SSE e la silhouette sono al di fuori di quattro deviazioni standard dal valor medio, ciò assicura che i dati ottenuti sono esterni al $99.994\%$  delle relative distribuzioni.
Dalle immagini seguenti si evince che tutti i valori ottenuti sono compatibili con una clusterizzazione non random.

\begin{figure}[H]
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSSE_1.png}
\caption{Distribuzione dell'SSE su 500 set di dati random per il sottoinsieme 1. Media: 250; Deviazione Standard: 3. La linea arancione rappresenta l'SSE sui dati reali.  }
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSilhouette_1.png}
\caption{Distribuzione della silhouette su 500 set di dati random per il sottoinsieme 1. Media: 0.156; Deviazione Standard: 0.003. La linea arancione rappresenta la silhouette sui dati reali.}
\label{etichetta2}
\end{minipage}
\end{figure}
\begin{figure}[H]
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSSE_2.png}
\caption{Distribuzione dell'SSE su 500 set di dati random per il sottoinsieme 2. Media: 250; Deviazione Standard: 3. La linea arancione rappresenta l'SSE sui dati reali.}
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSilhouette_2.png}
\caption{Distribuzione della silhouette su 500 set di dati random per il sottoinsieme 2. Media: 0.156; Deviazione Standard: 0.003. La linea arancione rappresenta la silhouette sui dati reali. }
\label{etichetta2}
\end{minipage}
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSSE_3.png}
\caption{Distribuzione dell'SSE su 500 set di dati random per il sottoinsieme 3. Media: 178; Deviazione Standard: 3. La linea arancione rappresenta l'SSE sui dati reali.  }
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSilhouette_3.png}
\caption{Distribuzione della silhouette su 500 set di dati random per il sottoinsieme 3. Media: 0.200; Deviazione Standard: 0.004. La linea arancione rappresenta la silhouette sui dati reali.}
\label{etichetta2}
\end{minipage}
\end{figure}
\begin{figure}[H]
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSSE_4.png}
\caption{Distribuzione dell'SSE su 500 set di dati random per il sottoinsieme 4. Media: 250; Deviazione Standard: 3. La linea arancione rappresenta l'SSE sui dati reali.}
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSilhouette_4.png}
\caption{Distribuzione della silhouette su 500 set di dati random per il sottoinsieme 4. Media: 0.156; Deviazione Standard: 0.003. La linea arancione rappresenta la silhouette sui dati reali. }
\label{etichetta2}
\end{minipage}
\end{figure}



\subsection{DB-Scan}
Per quanto riguarda il DB-Scan i sottoinsiemi che sono stati utilizzati :\\
\begin{enumerate}
\item PercentSalaryHike, FractionYearsAtCompany, YearsInCurrentRole, RateIncome
\item PercentSalaryHike, FractionYearsAtCompany, RateIncome, YearsInCurrentRole, NumCompaniesWorked
\item DistanceFromHome, FractionYearsAtCompany, RateIncome, YearsInCurrentRole, TrainingTimesLastYear
\end{enumerate}

La sensibilità dell'algoritmo alla scelta dei parametri è molto più elevata rispetto al K-Means. L'approccio utilizzato è stato quello di far variare il numero di min samples tra $5$ e $20$ e, attraverso il grafico dell'elbow curve, è stato scelto il valore di $eps$ in prossimità del gomito. Successivamente è stato fatto variare il valore di $eps$ su una scala molto fine in un suo intorno.

\begin{figure}[H]
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{Figure_1.png}
\caption{Elbow curve con min samples =  8 }
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{Figure_24.png}
\caption{eps = 0.750 , silhoutte = 0.26 }
\label{etichetta2}
\end{minipage}
\end{figure}


\begin{figure}[H]
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{2.png}
\caption{Elbow curve con min samples =  8}
\label{etichetta1}
\centering
\includegraphics[width=\textwidth]{5 (1).png}
\caption{Elbow curve con min samples =  15}
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{22.png}
\caption{eps = 0.950, silhoutte = 0.12 }
\label{etichetta2}
\centering
\includegraphics[width=\textwidth]{5 (2).png}
\caption{eps = 1.20, silhoutte = 0.02}
\label{etichetta2}
\end{minipage}
\end{figure}

Come si può notare dai grafici l'algoritmo è riuscito ad evidenziare un diverso numero di cluster ed un certo numero di noise points (punti viola). Questo è essenzialmente dovuto alla distribuzione dei valori nello spazio tridimensionale: essi formano infatti delle slices molto dense a valori fissati di uno dei tre attributi, come si può ad esempio osservare nella Figura 33. In questo caso inoltre si nota che il valore della silhoutte è praticamente nullo e ciò implica che la divisione ottenuta è totalmente inconsistente. Per tali motivi non è stato possibile associare ai cluster alcun significato.

\subsubsection{Validazione}
La validazione è stata eseguita anche in questo caso tramite la costruzione di $N=500$ distribuzioni random su cui si è valutata la silhouette. La clusterizzazione è stata considerata non random se il valore ottenuto della silhouette è al di fuori di quattro deviazioni standard dal valor medio, quindi esterno al $99.994\%$ della distribuzione.

\begin{figure}[H]
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSilhouetteDBSCAN_1.png}
\caption{Distribuzione della silhouette su 500 set di dati random per il sottoinsieme 1. Media: 0.06; Deviazione Standard: 0.03. La linea arancione rappresenta la silhouette sui dati reali.  }
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{RandomSilhouette_1.png}
\caption{Distribuzione della silhouette su 500 set di dati random per il sottoinsieme 1. Media: 0.156; Deviazione Standard: 0.003. La linea arancione rappresenta la silhouette sui dati reali.}
\label{etichetta2}
\end{minipage}
\end{figure}

\subsection{Hierarchical}
Per quanto riguarda il Hierarchical i sottoinsiemi che hanno mostrato i risultati migliori sono:

\begin{enumerate}
\item DistanceFromHome, Age, MonthlyIncome
\item PercentSalatyHike, TrainingTimeLastYear, MonthlyIncome, Age
\end{enumerate}

Per entrambi sono stati usati algoritmi di tipo agglomerativo con diverse definizioni della distanza inter clusters.
Di seguito sono riportati i metodo usati per ciascun sottoinsieme e i rispettivi dendogrammi.

\begin{itemize}
\item Sottoinsieme 1: Group Average, Ward.
\item Sottoinsieme 2: Median, Ward.
\end{itemize}

\begin{figure}[H]
\begin{minipage}[H]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{DistanceFromHome,Age,MonthlyIncome035Average.png}
\caption{Dendogramma sottoinsieme 1:  metodo = Group Average; silhouette = 0.35}
\label{etichetta1}
\centering
\includegraphics[width=\textwidth]{hierarchical_df3.png}
\caption{Dendogramma sottoinsieme 2:  metodo = Median; silhouette = 0.37}
\label{etichetta1}
\end{minipage}
\hfill
\begin{minipage}[H]{0.45\textwidth}
\centering
\includegraphics[width=\textwidth]{DistanceFromHome,Age,MonthlyIncome035Ward.png}
\caption{Dendogramma sottoinsieme 1:  metodo = Ward; silhouette = 0.35  }
\label{etichetta2}
\centering
\includegraphics[width=\textwidth]{dendogram_hierarchicaldf3(ward).png}
\caption{Dendogramma sottoinsieme 2:  metodo = Ward; silhouette = 0.24}
\label{etichetta2}
\end{minipage}
\end{figure}











%\section{Conclusioni}
\end{document}

